- 任务说明：文本文本索引的实现逻辑
- 任务要求：
    - 理解倒排索引
    - 实现 TFIDF 和 BM25 的编码与检索
- 打卡要求：使用 TFIDF 和 BM25 进行检索，使用 question 检索到答案的 reference 页面位置
## 文本检索流程

文本检索是一个多步骤的过程，其核心是构建倒排索引以实现高效的文本检索：

- 步骤 1（文本预处理）：在文本预处理阶段，对原始文本进行清理和规范化，包括去除停用词、标点符号等噪声，并将文本统一转为小写。接着，采用词干化或词形还原等技术，将单词转换为基本形式，以减少词汇的多样性，为后续建立索引做准备。
- 步骤 2（文本索引）：构建倒排索引是文本检索的关键步骤。通过对文档集合进行分词，得到每个文档的词项列表，并为每个词项构建倒排列表，记录包含该词项的文档及其位置信息。这种结构使得在查询时能够快速找到包含查询词的文档，为后续的文本检索奠定了基础。
- 步骤 3（文本检索）：接下来是查询处理阶段，用户查询经过预处理后，与建立的倒排索引进行匹配。计算查询中每个词项的权重，并利用检索算法（如 TFIDF 或 BM25）对文档进行排序，将相关性较高的文档排在前面。

在实际应用中，倒排索引的构建和维护需要考虑性能问题，采用一些优化技术来提高检索效率，如压缩倒排索引、分布式索引等。这些步骤共同构成了一个有序而逻辑完整的文本检索流程。

![[Pasted image 20240330120914.png|600]]

Forward Index 就是每篇文章里面有哪些词语，Inverted Index 倒排表 就是每个词语存在于哪些文章中
## 文本检索与语义检索

下面是文本检索和语义检索的区别和联系的表格形式：

| |文本检索|语义检索|
|---|---|---|
|**定义**|通过关键词或短语匹配文本数据的过程|强调理解查询与文本之间的深层语义关系|
|**方法**|基于关键词匹配，使用 TFIDF、BM25 等权重计算|使用 NLP 技术，如词嵌入、预训练的语言模型|
|**特点**|强调字面意义，关注表面文本的匹配|关注词语之间的关联、语境和含义|
|**应用场景**|大规模文本数据的快速匹配|对语义理解要求较高的场景|
|**优势**|处理速度较快，适用于大规模文本数据|能够处理一词多义、近义词等语义上的复杂情况|
|**联系**|结合使用，先使用文本检索筛选出候选文档，然后在这些文档上应用语义检索|可以利用语义模型提取关键词的上下文信息，提升检索效果|

在一些场景中，文本检索和语义检索可以结合使用，以充分利用它们各自的优势。例如，可以先使用文本检索筛选出候选文档，然后在这些文档上应用语义检索来进一步提高检索的准确性。当然具体使用哪种检索方法，需要具体分析，在 RAG 中可以结合两种方法一起进行使用。

文本检索基于关键词，可以将其看作绝对匹配。
## TFIDF

TFIDF（Term Frequency-Inverse Document Frequency）是一种用于信息检索和文本挖掘的常用权重计算方法，旨在衡量一个词项对于一个文档集合中某个文档的重要性。该方法结合了两个方面的信息：词项在文档中的频率（TF）和在整个文档集合中的逆文档频率（IDF）。

1. **词项在文档中的频率（TF）**：
$$
TF(t, d) = \frac{\text{词项t在文档d中出现的次数}}{\text{文档d中所有词项的总数}}
$$
其中，$t$ 表示词项，$d$ 表示文档。TF 表示了一个词项在文档中的相对频率，即在文档中出现的次数相对于文档总词项数的比例。

2. **逆文档频率（IDF）**：
$$
IDF(t) = \log\left(\frac{\text{文档集合中的文档总数}}{\text{包含词项t的文档数 + 1}}\right)
$$
其中，$t$ 表示词项。IDF 表示了一个词项在整个文档集合中的稀有程度，如果词项在许多文档中都出现，其 IDF 值较低，反之则较高。

3. **TFIDF 的计算**：
$$
TFIDF(t, d, D) = TF(t, d) \times IDF(t)
$$
其中，$D$ 表示文档集合。TFIDF 的最终值是将词项在文档中的频率和在整个文档集合中的逆文档频率相乘，这样可以得到一个更全面的评估，既考虑了在文档中的重要性，也考虑了在整个文档集合中的稀有性。
```python
import jieba
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import normalize

# 对提问和PDF内容进行分词
question_words = [' '.join(jieba.lcut(x['question'])) for x in questions]
pdf_content_words = [' '.join(jieba.lcut(x['content'])) for x in pdf_content]

tfidf = TfidfVectorizer()
tfidf.fit(question_words + pdf_content_words)

# 提取TFIDF
question_feat = tfidf.transform(question_words)
pdf_content_feat = tfidf.transform(pdf_content_words)

# 进行归一化
question_feat = normalize(question_feat)
pdf_content_feat = normalize(pdf_content_feat)

# 检索进行排序
for query_idx, feat in enumerate(question_feat):
    score = feat @ pdf_content_feat.T
    score = score.toarray()[0]
    max_score_page_idx = score.argsort()[-1] + 1
    questions[query_idx]['reference'] = 'page_' + str(max_score_page_idx)

# 生成提交结果
# https://competition.coggle.club/
with open('submit.json', 'w', encoding='utf8') as up:
    json.dump(questions, up, ensure_ascii=False, indent=4)
```
## BM25

BM25Okapi 是 BM25 算法的一种变体，它在信息检索中用于评估文档与查询之间的相关性。以下是 BM25Okapi 的原理和打分方式的概述：

1. BM25Okapi 的主要参数：
- $k_1$：控制词项频率对分数的影响，通常设置为 1.5。
- $b$：控制文档长度对分数的影响，通常设置为 0.75。
- $epsilon$：用于防止逆文档频率（IDF）为负值的情况，通常设置为 0.25。

2. 打分的计算过程：
BM25Okapi 的打分过程基于以下三个因素：词项在文档中的频率（TF）、文档的长度（doc_len）以及逆文档频率（IDF）。
- TF（词项在文档中的频率）
- IDF（逆文档频率）
- 文档长度（doc_len）

文档长度对分数的影响通过 $b$ 控制。文档长度越长，该项的分数越小。BM25Okapi 的打分公式综合考虑了以上三个因素，通过对每个词项的打分求和得到最终的文档与查询的相关性分数。
$$
\text{score} = \sum_{q \in \text{query}} \left( \text{IDF}(q) \cdot \frac{q\_freq \cdot (k1 + 1)}{q\_freq + k1 \cdot (1 - b + b \cdot \frac{\text{doc\_len}}{\text{avgdl}})} \right)
$$
其中，$\text{avgdl}$ 是文档集合中的平均文档长度。BM25Okapi通过合理调整参数，兼顾了词项频率、文档长度和逆文档频率，使得在信息检索任务中能够更准确地评估文档与查询之间的相关性，提高检索效果。
```python
# !pip install rank_bm25
import jieba
import numpy as np
from rank_bm25 import BM25Okapi

pdf_content_words = [jieba.lcut(x['content']) for x in pdf_content]

bm25 = BM25Okapi(pdf_content_words)

for query_idx in range(len(questions)):
  doc_scores = bm25.get_scores(jieba.lcut(questions[query_idx]["question"]))
  max_score_page_idx = doc_scores.argsort()[::-1][0]+1
  questions[query_idx]['reference'] = 'page_' + str(max_score_page_idx)

with open('wonder_bm25_retrieval_top1.json','w',encoding='utf8') as up:
  json.dump(questions,up,ensure_ascii=False,indent=4)

for query_idx in range(len(questions)):
  doc_scores = bm25.get_scores(jieba.lcut(questions[query_idx]["question"]))
  max_score_page_idx = doc_scores.argsort()[::-1]+ 1
  questions[query_idx]['reference'] = ['page_' + str(x) for x in max_score_page_idx[:10]]

with open('wonder_bm25_retrieval_top10.json','w',encoding='utf8')as up:
  json.dump(questions,up,ensure_ascii=False,indent=4)
```
## 注意事项

1. **实现非工业级别**：
    - 提供的 TFIDF 和 BM25 的实现并非工业级别，仅作为演示目的。在实际进行文本检索时，特别是在大规模数据集和生产环境中，应该使用专业的文本检索引擎工具，例如 Elasticsearch，以确保高效、可扩展和内存友好的实现。
2. **相似度计算的内存和数据量级考虑**：
    - 在实际应用中，对整个文本集合构建矩阵并进行相似度计算可能导致内存占用较大，尤其在大规模数据集情况下。建议考虑使用基于倒排索引等数据结构的文本检索引擎，以减小内存占用并提高检索效率。
3. **停用词和单词筛选**：
    - 未对文本进行停用词筛选和额外的单词筛选。在实际应用中，建议进行停用词的去除，以排除常见但无实际意义的词汇，提高检索的准确性。同时，考虑引入领域专有的单词筛选，以过滤掉与任务无关的词汇，优化检索结果。
4. **PDF 处理方式**：
    - 将 PDF 内每一页都当做一个文档进行处理。实际应用中，对于 PDF 文档，可以考虑使用专业的 PDF 文本提取工具，提取有意义的文本内容，而不是将每一页都当做独立的文档处理。这有助于更好地利用文档内部的语义信息。