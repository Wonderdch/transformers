- 任务说明：对用户的提问提取关键词
- 任务要求：
    - 计算提问与现有文档的相似度
    - 构造 prompt 完成意图识别
- 打卡要求：完成 RAG 完整流程，并提交结果进行打分

文本关键词抽取是自然语言处理领域的一项重要任务，其目标是从给定的文本中提取出最具代表性和有意义的单词或短语。这些关键词通常反映了文本的主题、内容或重要信息。常见的步骤包括分词、词性标注、停用词移除、计算词语权重以及关键词抽取算法等过程。

[![](Attachment/e0b1afce456b26f895ba09e2c282611080961297_2_690x190.png)
## 方法 1：IDF

1. **分词（Tokenization）：** 将文本拆分为单词或短语。这一步骤将文本转换为基本的语言单元，为后续的处理做准备。
    
2. **移除通用词（Stopword Removal）：** 剔除常见的停用词，如"and"、“the”、"is"等，这些词在文本中普遍出现但往往没有实际的信息价值。这样做可以减少噪音，使关键词更集中在文本的内容性词汇上。
    
3. **计算逆文档频率（IDF）：** 对于每个单词，计算其逆文档频率。逆文档频率是一个衡量单词重要性的指标，它通过对整个文本集合中包含该词的文档数取倒数来计算。
    
4. **计算 TF-IDF 得分：** 对于每个单词，计算其 TF-IDF 得分，即词频（TF）与逆文档频率（IDF）的乘积。TF 表示单词在当前文档中的出现频率。
    
5. **排序和选取关键词：** 根据计算得到的 TF-IDF 得分对单词进行排序，选择排名前几的单词作为关键词。排名越高的单词表示在当前文档中具有更高的重要性。
    
## 方法 2：KeyBERT

- [MaartenGr/KeyBERT: Minimal keyword extraction with BERT (github.com)](https://github.com/MaartenGr/KeyBERT)
- 从文档中提取关键词后，计算每个关键词与整个文档的相似度，相似度越高，该关键词越能代表整个文档

![[Pasted image 20240401120956.png|1100]]
1. **Embedding 文本：** 首先，KEYBERT 使用预训练的 BERT 模型，例如 `distilbert-base-nli-mean-tokens`，将输入的文本嵌入到一个高维的向量空间中。BERT 模型能够学习丰富的语义表示，因此生成的向量能够捕捉文本的语义信息。
    
2. **计算余弦相似度：** 然后，KEYBERT 计算文档中每个候选关键词或关键短语与整个文档之间的余弦相似度。余弦相似度是一种衡量两个向量之间夹角的度量，它在这里用于度量嵌入向量之间的相似性。
    
3. **排序关键词：** 最后，根据计算得到的余弦相似度值，KEYBERT 将关键词或关键短语排序，从而形成最终的关键词列表。余弦相似度越高，表示关键词与文档的语义相似度越大，因此在排序中位置越靠前。
    
## 方法 3：Prompt 关键词提取

```
你是一个专业的文本理解专家，现在请你识别下面内容中的关键词，将关键词使用空格隔开：

{输入文本}
```

[![](Attachment/c50a7aefac22ec580a75ebf39fbe451169764299_2_411x500.png)

为了提高关键词提取过程的效率，可以采用一种优化策略。首先，将所有文档通过预训练的嵌入模型映射到向量空间中，生成它们的向量表示。接着，通过计算文档之间的相似性，使用余弦相似度等度量方法，将相似的文档聚合成一个文档聚类。在每个文档聚类中，选择一个代表性文档，利用关键词提取模型生成关键词。