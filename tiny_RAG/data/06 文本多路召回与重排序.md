- 任务说明：实现多种文本编码和检索逻辑，并进行重排序
- 任务要求：
    - 结合文本索引和向量检索结果
    - 加载重排序模型，对检索进行重排序
- 打卡要求：完成多路召回与重排序，与任务 5 精度进行对比
## 多路召回逻辑

多路召回逻辑是在文本检索中常用的一种策略，其目的是通过多个召回路径（或方法）综合获取候选文档，以提高检索的全面性和准确性。单一的召回方法可能由于模型特性或数据特点而存在局限性，多路召回逻辑引入了多个召回路径，每个路径采用不同的召回方法。

- 实现方法 1：将 BM25 的检索结果 和 语义检索结果 按照排名进行加权
- 实现方法 2：按照段落、句子、页不同的角度进行语义编码进行检索，综合得到检索结果。

[![|800](Attachment/8ea5606067e76a98c594faf85ee00cc3228b7943_2_690x345.webp)
`
```python
import json
bge = json.load(open('wonder_bge_sgement_retrieval_top10.json'))
bm25 = json.load(open('wonder_bm25_retrieval_top10.json'))

fusion_result =[]
k = 60
for q1,q2 in zip(bge,bm25):
  fusion_score = {}
  for idx, q in enumerate(q1['reference']):
    if q not in fusion_score:
      fusion_score[q]= 1 /(idx +k)
    else:
      fusion_score[q]+=1/(idx + k)
  for idx,q in enumerate(q2['reference']):
    if q not in fusion_score:
      fusion_score[q]=1/(idx +k)
    else:
      fusion_score[q]+=1/(idx+k)
  
  sorted_dict = sorted(fusion_score.items(),key=lambda item:item[1],reverse=True)
  q1['reference'] = sorted_dict[0][0]
  fusion_result.append(q1)

with open('wonder_fusion_bge+bm25_retrieval.json','w',encoding='utf8')as up:
  json.dump(fusion_result,up,ensure_ascii=False,indent=4)
```

- k = 60 是个经验值
- 实践中发现 BM25 + 一个比较好的文本嵌入模型 的结果就足够好了，再加入更多，反而性能下降
## 重排序逻辑（BM25 + BGE Rerank）

重排序逻辑是文本检索领域中一种重要的策略，主要用于优化原有文本检索方法返回的候选文档顺序，以提高最终的检索效果。在传统的文本检索方法中，往往采用打分的逻辑，如计算 BERT 嵌入向量之间的相似度。而重排序逻辑引入了更为复杂的文本交叉方法，通过特征交叉得到更进一步的打分，从而提高排序的准确性。

[![](Attachment/8b9e4fa4629a153fb5ab9a571d131565d9f3a593.png)

- 重排序逻辑常常使用更为强大的模型，如交叉编码器（cross-encoder）模型。这类模型能够更好地理解文本之间的交叉关系，捕捉更复杂的语义信息。
- 首先通过传统的嵌入模型获取初始的 Top-k 文档，然后使用重排序逻辑对这些文档进行重新排序。这样可以在保留初步筛选文档的基础上，更精确地排列它们的顺序。

```python
import jieba, json, pdfplumber
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import normalize
from sentence_transformers import SentenceTransformer
from transformers import AutoModelForSequenceClassification,AutoTokenizer
import torch

# 读取数据集
questions = json.load(open("questions.json"))
pdf = pdfplumber.open("初赛训练数据集.pdf")
pdf_content = []
for page_idx in range(len(pdf.pages)):
    pdf_content.append({
        'page': 'page_' + str(page_idx + 1),
        'content': pdf.pages[page_idx].extract_text()
    })

# 加载重排序模型
tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')
rerank_model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')
# rerank_model.cuda()
rerank_model.eval()

# 进行召回合并
bge = json.load(open('wonder_bge_sgement_retrieval_top10.json'))
bm25 = json.load(open('wonder_bm25_retrieval_top10.json'))

fusion_result =[]
k = 60
for q1,q2 in zip(bge,bm25):
  print(len(fusion_result), len(bge))
  fusion_score = {}
  for idx, q in enumerate(q1['reference']):
    if q not in fusion_score:
      fusion_score[q] = 1 / (idx +k)
    else:
      fusion_score[q] += 1 / (idx + k)

  for idx,q in enumerate(q2['reference']):
    if q not in fusion_score:
      fusion_score[q] = 1 / (idx +k)
    else:
      fusion_score[q] += 1 / (idx+k)

  sorted_dict = sorted(fusion_score.items(), key=lambda item:item[1], reverse=True)
  pairs = []
  # 将用户提问和回答内容拼接为文本对
  for sorted_result in sorted_dict[:3]:
    page_index = int(sorted_result[0].split('_')[1]) - 1
    pairs.append([q1["question"], pdf_content[page_index]['content']])
  
  # 对文本对进行统一编码
  inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)
  # 编码后进行正向传播，完成打分
  with torch.no_grad():
    inputs = {key: inputs[key] for key in inputs.keys()}
    scores = rerank_model(**inputs, return_dict=True).logits.view(-1, ).float()

  # sorted_result = sorted_dict[scores.cpu().numpy().argmax()]
  sorted_result = sorted_dict[scores.numpy().argmax()]
  q1['reference'] = sorted_result[0]

  fusion_result.append(q1)

with open('wonder_fusion_bge+bm25_rerank_retrieval.json', 'w', encoding='utf8') as up:
    json.dump(fusion_result, up, ensure_ascii=False, indent=4)
```